# main_processor.py (LangChain ë²„ì „)
import sys
from typing import Dict, Any, List
import time

# import os

# current_dir = os.path.dirname(os.path.abspath(__file__))      # í˜„ì¬ langchain í´ë”
# project_root = os.path.abspath(os.path.join(current_dir, ".."))  # TEST_RAG
# sys.path.insert(0, project_root)

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain.embedding_generator import EmbeddingGenerator
from langchain.redis_handler import RedisVectorSearchHandler, SemanticCacheHandler

# ê°œë°œì ìˆ˜ì • ê°€ëŠ¥ ë³€ìˆ˜ (ì˜ˆì‹œ)
user_query = "ì¢…ì´ ë¹¨ëŒ€ì— í”Œë¼ìŠ¤í‹± ì½”íŒ…ì„ ì‚¬ìš©í•˜ëŠ” ì´ìœ ì™€ ê·¸ë¡œ ì¸í•œ ë‹¨ì ì€ ë­”ê°€ìš”?"

# ìœ ì‚¬ë„ ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìœ ì‚¬í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼)
SIMILARITY_THRESHOLD = 0.4


class MainProcessor:
    """LangChain ê¸°ë°˜ RAG ì‹œìŠ¤í…œì˜ ë©”ì¸ ì²˜ë¦¬ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ (ë¦¬íŒ©í† ë§)"""

    def __init__(self, redis_url: str = 'redis://localhost:6379'):
        """
        ë©”ì¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”

        Args:
            redis_url (str): Redis ì„œë²„ URL
        """
        try:
            # ì„ë² ë”© ìƒì„±ê¸° ë° Redis í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
            self.embedding_generator = EmbeddingGenerator()
            self.redis_handler = RedisVectorSearchHandler(
                embedding_model=self.embedding_generator.embeddings,
                redis_url=redis_url,
                index_name="document_index"
            )
            self.semantic_cache = SemanticCacheHandler(
                embedding_model=self.embedding_generator.embeddings,
                redis_url=redis_url
            )
            print("ë©”ì¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"ë©”ì¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            sys.exit(1)

    def process(self, query: str) -> Dict[str, Any]:
        """
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ ë˜ëŠ” ì €ì¥ì„ ìˆ˜í–‰

        Args:
            query (str): ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            Dict[str, Any]: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
        """
        result = {
            "success": False,
            "operation": None,
            "message": "",
            "similar_items": [],
            "cache_answer": None,
            "vector_search_results": [],
            "final_answer": None
        }
        print("hello")
        print(self.redis_handler.get_all_stored_documents())
        # 1. ì‹œë©˜í‹± ìºì‹œ ê²€ìƒ‰
        cache_results = self.semantic_cache.search_similar_question(
            query=query,
            score_threshold=0.05
        )
        if cache_results:
            best = max(cache_results, key=lambda x: x["similarity"])
            result["operation"] = "cache_hit"
            result["cache_answer"] = best["answer"]
            result["success"] = True
            result["message"] = "ì‹œë©˜í‹± ìºì‹œì—ì„œ ë‹µë³€ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
            result["final_answer"] = best["answer"]
            return result

        # 2. ë²¡í„° ê²€ìƒ‰ (ë¬¸ì„œ ê¸°ë°˜ ê·¼ê±° íƒìƒ‰)
        vector_results = self.redis_handler.search_similar_embeddings(
            query_text=query,
            top_k=3,
            similarity_threshold=0.4
        )
        result["vector_search_results"] = vector_results

        # 3. ë‹µë³€ ìƒì„± (ì—¬ê¸°ì„  ì„ì‹œ ë‹µë³€)
        generated_answer = f"[ì„ì‹œ ë‹µë³€] '{query}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤."
        # 4. ìºì‹œì— ì €ì¥
        self.semantic_cache.save_qa_pair(
            question=query,
            answer=generated_answer,
            metadata={"source": "gpt", "timestamp": time.time()}
        )
        result["operation"] = "cache_miss_saved"
        result["cache_answer"] = generated_answer
        result["success"] = True
        result["message"] = "ìƒˆ ë‹µë³€ì„ ìƒì„±í•˜ì—¬ ì‹œë©˜í‹± ìºì‹œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤."
        result["final_answer"] = generated_answer
        return result

    def display_results(self, result: Dict[str, Any]) -> None:
        """
        ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì½˜ì†”ì— ì¶œë ¥

        Args:
            result (Dict[str, Any]): ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
        """
        if not result["success"]:
            print(f"\nâŒ ì˜¤ë¥˜: {result['message']}")
            return

        if result["operation"] == "cache_hit":
            print("\nğŸ” [ì‹œë©˜í‹± ìºì‹œ HIT] ë‹µë³€:")
            print("-" * 80)
            print(result["cache_answer"])
            print("-" * 80)
        elif result["operation"] == "cache_miss_saved":
            print("\nğŸ’¾ [ì‹œë©˜í‹± ìºì‹œ MISS] ìƒˆ ë‹µë³€ ì €ì¥:")
            print("-" * 80)
            print(result["cache_answer"])
            print("-" * 80)
            print("\n[ë²¡í„° ê²€ìƒ‰ ê²°ê³¼]")
            for idx, item in enumerate(result["vector_search_results"], 1):
                print(f"{idx}. {item['metadata'].get('text', '')} (ìœ ì‚¬ë„: {item['similarity']:.2f})")
            print("-" * 80)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë©”ì¸ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    processor = MainProcessor()

    # í˜„ì¬ ì„¤ì •ëœ ì…ë ¥ê°’ í‘œì‹œ
    print("\n=== RAG í”„ë¡œì„¸ì„œ ì‹¤í–‰ ===")
    print(f"ì§ˆë¬¸: {user_query}")
    print("=" * 80)

    # ì²˜ë¦¬ ì‹¤í–‰
    result = processor.process(
        query=user_query,
    )

    # ê²°ê³¼ ì¶œë ¥
    processor.display_results(result)


if __name__ == "__main__":
    main()